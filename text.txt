<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Emotion Detection AI</title>

  <!-- Face API -->
  <script defer src="https://unpkg.com/face-api.js"></script>

  <style>
    body {
      background: #111;
      color: white;
      text-align: center;
      font-family: Arial;
    }
    video, canvas {
      position: absolute;
      left: 50%;
      transform: translateX(-50%);
    }
    h1 {
      margin-top: 20px;
    }
  </style>
</head>

<body>

<h1>Facial Emotion Detection AI</h1>
<p>Runs fully in browser (iPad supported)</p>

<video id="video" width="720" height="560" autoplay muted></video>

<script>
  const video = document.getElementById('video');

  Promise.all([
    faceapi.nets.tinyFaceDetector.loadFromUri(
      'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/'
    ),
    faceapi.nets.faceExpressionNet.loadFromUri(
      'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/'
    )
  ]).then(startVideo);

  function startVideo() {
    navigator.mediaDevices.getUserMedia({ video: {} })
      .then(stream => {
        video.srcObject = stream;
      })
      .catch(err => console.error(err));
  }

  video.addEventListener('play', () => {
    const canvas = faceapi.createCanvasFromMedia(video);
    document.body.append(canvas);

    const displaySize = { width: video.width, height: video.height };
    faceapi.matchDimensions(canvas, displaySize);

    setInterval(async () => {
      const detections = await faceapi
        .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceExpressions();

      const resized = faceapi.resizeResults(detections, displaySize);
      canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);

      faceapi.draw.drawDetections(canvas, resized);
      faceapi.draw.drawFaceExpressions(canvas, resized);
    }, 200);
  });
</script>

</body>
</html>